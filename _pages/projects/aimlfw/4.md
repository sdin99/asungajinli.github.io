---
layout: posts
title: "Kserve를 통해 모델 배포하기"
permalink: /projects/aimlfw/4/
prev: aimlfw
---

Documentation: [Install Kserve](https://docs.o-ran-sc.org/projects/o-ran-sc-aiml-fw-aimlfw-dep/en/latest/installation-guide.html#install-only-kserve-for-deploying-models){:target="_blank"}

위 링크를 참고하여 Kserve를 설치하고 모델을 배포해보자. 아래 내용은 위 링크를 참고하여 작성되었다.

1. Kserve 설치

    `aimlfw-dep` 디렉토리로 가서

    ```bash
    bin/install-kserve.sh
    ```

2. QoE 모델 배포

    먼저 네임스페이스를 생성한다.

    ```bash
    kubectl create namespace kserve-test
    ```

    `qoe.yaml` 파일을 생성해서 아래 내용을 넣어준다.

    ```yaml
    apiVersion: "serving.kserve.io/v1beta1"
    kind: "InferenceService"
    metadata:
      name: qoe-model
    spec:
      predictor:
        tensorflow:
          storageUri: "<update Model URL here>"
          runtimeVersion: "2.5.1"
          resources:
            requests:
              cpu: 0.1
              memory: 0.5Gi
            limits:
              cpu: 0.1
              memory: 0.5Gi
    ```

    `storageUri`에 모델 URL을 넣을 때 localhost 대신 tm.traininghost를 넣어주자.

    나는 localhost로 했을 때 `storage-initializer`에서 `connection refused` 오류가 발생했다.

    ```bash
    kubectl apply -f qoe.yaml -n kserve-test
    ```

    그런데 아마 kserve-test에 pod가 생기지 않았을 것이다.

    ```bash
    kubectl describe inferenceservice qoe-model -n kserve-test
    ```

    로 오류를 확인해보자.

    ```bash
    no runtime found to support predictor with model type: {tensorflow <nil>}
    ```

    이런 메시지가 뜨는데, runtime을 찾을 수 없다는 오류가 뜬다.

    [Kserve github repository](https://github.com/kserve/kserve/blob/master/install/v0.12.1/kserve-cluster-resources.yaml){:target="_blank"} 로 가 `kserve-cluster-resources.yaml` 로 runtime을 설치해주자.

    나는 최신 버전인 `v0.12.1`을 사용했다.

    ```bash
    kubectl apply -f https://raw.githubusercontent.com/kserve/kserve/master/install/v0.12.1/kserve-cluster-resources.yaml
    ```

    runtime이 잘 올라갔는지 확인해보자.

    ```bash
    kubectl get clusterservingruntimes
    ```

    이제 다시 모델을 배포해보자.

    우선 기존 qoe-model을 삭제한다.

    ```bash
    kubectl delete inferenceservice qoe-model -n kserve-test
    ```

    그리고 다시 모델을 배포한다.

    ```bash
    kubectl apply -f qoe.yaml -n kserve-test
    ```

    확인해보면

    ```bash
    $ kubectl get pods -n kserve-test

    NAME                                                    READY   STATUS    RESTARTS   AGE
    qoe-model-predictor-00001-deployment-6d895c7889-x8rhc   2/2     Running   0          45m
    ```

    ```bash
    $ kubectl get inferenceservice qoe-model -n kserve-test

    NAME        URL                                              READY   PREV   LATEST   PREVROLLEDOUTREVISION   LATESTREADYREVISION         AGE
    qoe-model   http://qoe-model.kserve-test.svc.cluster.local   True           100                              qoe-model-predictor-00001   47m
    ```

    이런 식으로 pod가 잘 올라간 것을 확인할 수 있다.

3. 예측